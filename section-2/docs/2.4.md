# Asynchronous Communications and Message Queues

## Overview

This topic explores asynchronous communication patterns in microservices architecture using message queues, event-driven systems, and pub-sub patterns. We'll implement Apache Kafka as our message broker and demonstrate real-world scenarios like order processing notifications, user activity tracking, and inter-service event handling.

## Learning Objectives

- Understand asynchronous vs synchronous communication patterns
- Implement Apache Kafka for message queuing
- Create event-driven microservices architecture
- Handle message ordering, delivery guarantees, and error handling
- Build resilient communication patterns with dead letter queues
- Implement event sourcing and CQRS patterns

## Synchronous vs Asynchronous Communication

### 1. Communication Pattern Comparison

```
┌─────────────────────────────────────────────────────────┐
│           SYNCHRONOUS vs ASYNCHRONOUS                  │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  Synchronous (Request-Response):                       │
│  ┌─────────────────────────────────────────────────────┐│
│  │                                                     ││
│  │  Client ──────── Request ────────▶ Service         ││
│  │    │                                │              ││
│  │    │         ◀── Response ──────────┘              ││
│  │    │                                               ││
│  │    └── Waits for response (Blocking)               ││
│  │                                                     ││
│  │  Characteristics:                                   ││
│  │  • Immediate response required                      ││
│  │  • Tight coupling between services                  ││
│  │  • Cascading failures possible                      ││
│  │  • Simple error handling                            ││
│  │  • Direct data consistency                          ││
│  └─────────────────────────────────────────────────────┘│
│                                                         │
│  Asynchronous (Message-Based):                        │
│  ┌─────────────────────────────────────────────────────┐│
│  │                                                     ││
│  │  Producer ── Message ──▶ Queue ──▶ Consumer        ││
│  │    │                      │          │             ││
│  │    └── Continues ──────┘  │          │             ││
│  │        (Non-blocking)     │          │             ││
│  │                           │          │             ││
│  │        ┌─ Message Store ───┘          │             ││
│  │        └── Persistence & Reliability  │             ││
│  │                                       │             ││
│  │  Characteristics:                     │             ││
│  │  • Eventual consistency               │             ││
│  │  • Loose coupling                     │             ││
│  │  • Better fault tolerance             │             ││
│  │  • Complex error handling             │             ││
│  │  • Scalable and resilient             │             ││
│  └─────────────────────────────────────────────────────┘│
│                                                         │
│  When to Use Each:                                     │
│  ┌─────────────────────────────────────────────────────┐│
│  │ Synchronous:                                        ││
│  │ • User authentication                               ││
│  │ • Real-time data queries                            ││
│  │ • Payment processing                                ││
│  │ • Critical validations                              ││
│  │                                                     ││
│  │ Asynchronous:                                       ││
│  │ • Email notifications                               ││
│  │ • Image processing                                  ││
│  │ • Analytics and logging                             ││
│  │ • Background tasks                                  ││
│  │ • Event broadcasting                                ││
│  └─────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────┘
```

### 2. Event-Driven Architecture Pattern

```
┌─────────────────────────────────────────────────────────┐
│              EVENT-DRIVEN ARCHITECTURE                 │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  Event Flow in E-commerce System:                     │
│                                                         │
│  1. Order Creation Event:                              │
│  ┌─────────────────────────────────────────────────────┐│
│  │ Order Service                                       ││
│  │      │                                              ││
│  │      │ Publishes: "OrderCreated"                    ││
│  │      ▼                                              ││
│  │ ┌─────────────┐                                     ││
│  │ │ Event Bus   │                                     ││
│  │ │  (Kafka)    │                                     ││
│  │ └─────────────┘                                     ││
│  │      │    │    │                                    ││
│  │   ┌──┘    │    └──┐                                 ││
│  │   ▼       ▼       ▼                                 ││
│  │ Payment  Inventory Notification                     ││
│  │ Service  Service   Service                          ││
│  └─────────────────────────────────────────────────────┘│
│                                                         │
│  2. Event Chain Reaction:                              │
│  ┌─────────────────────────────────────────────────────┐│
│  │                                                     ││
│  │ OrderCreated → PaymentProcessed → InventoryReserved ││
│  │      │               │                  │          ││
│  │      ▼               ▼                  ▼          ││
│  │ NotificationSent → EmailSent → SmssSent            ││
│  │                                                     ││
│  │ Each service:                                       ││
│  │ 1. Listens for relevant events                     ││
│  │ 2. Processes business logic                         ││
│  │ 3. May publish new events                           ││
│  │ 4. Updates its own data store                       ││
│  └─────────────────────────────────────────────────────┘│
│                                                         │
│  3. Event Structure:                                   │
│  ┌─────────────────────────────────────────────────────┐│
│  │ {                                                   ││
│  │   "eventId": "550e8400-e29b-41d4-a716-446655440000",││
│  │   "eventType": "OrderCreated",                      ││
│  │   "aggregateId": "order-12345",                     ││
│  │   "version": 1,                                     ││
│  │   "timestamp": "2023-12-01T10:00:00Z",              ││
│  │   "data": {                                         ││
│  │     "orderId": "12345",                             ││
│  │     "customerId": "customer-789",                   ││
│  │     "amount": 99.99,                                ││
│  │     "currency": "USD",                              ││
│  │     "items": [                                      ││
│  │       {                                             ││
│  │         "productId": "prod-456",                    ││
│  │         "quantity": 2,                              ││
│  │         "price": 49.99                              ││
│  │       }                                             ││
│  │     ]                                               ││
│  │   },                                                ││
│  │   "metadata": {                                     ││
│  │     "source": "order-service",                      ││
│  │     "correlationId": "req-789",                     ││
│  │     "causationId": "user-action-456"                ││
│  │   }                                                 ││
│  │ }                                                   ││
│  └─────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────┘
```

## Apache Kafka Implementation

### 1. Kafka Architecture and Setup

```
┌─────────────────────────────────────────────────────────┐
│                  KAFKA ARCHITECTURE                    │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  Kafka Cluster:                                        │
│  ┌─────────────────────────────────────────────────────┐│
│  │                 Broker 1                            ││
│  │ ┌─────────────┐ ┌─────────────┐ ┌─────────────────┐ ││
│  │ │  orders     │ │  payments   │ │ notifications   │ ││
│  │ │  Topic      │ │   Topic     │ │    Topic        │ ││
│  │ │             │ │             │ │                 │ ││
│  │ │ Part 0│Part 1│ │ Part 0│Part 1│ │  Part 0│Part 1 │ ││
│  │ └─────────────┘ └─────────────┘ └─────────────────┘ ││
│  └─────────────────────────────────────────────────────┘│
│                           │                             │
│  Producer Services:                                    │
│  ┌─────────────────────────────────────────────────────┐│
│  │ ┌─────────────┐ ┌─────────────┐ ┌─────────────────┐ ││
│  │ │Order Service│ │User Service │ │Product Service  │ ││
│  │ │             │ │             │ │                 │ ││
│  │ │ Publishes:  │ │ Publishes:  │ │ Publishes:      │ ││
│  │ │• OrderCreated│ │• UserRegist │ │• ProductUpdated │ ││
│  │ │• OrderPaid  │ │• UserLogin  │ │• PriceChanged   │ ││
│  │ └─────────────┘ └─────────────┘ └─────────────────┘ ││
│  └─────────────────────────────────────────────────────┘│
│                           │                             │
│  Consumer Services:                                    │
│  ┌─────────────────────────────────────────────────────┐│
│  │ ┌─────────────┐ ┌─────────────┐ ┌─────────────────┐ ││
│  │ │Notification │ │Analytics    │ │Audit Service    │ ││
│  │ │Service      │ │Service      │ │                 │ ││
│  │ │             │ │             │ │                 │ ││
│  │ │ Subscribes: │ │ Subscribes: │ │ Subscribes:     │ ││
│  │ │• OrderEvents│ │• AllEvents  │ │• AllEvents      │ ││
│  │ │• UserEvents │ │             │ │                 │ ││
│  │ └─────────────┘ └─────────────┘ └─────────────────┘ ││
│  └─────────────────────────────────────────────────────┘│
│                                                         │
│  Key Kafka Concepts:                                  │
│  • Topic: Category of messages                         │
│  • Partition: Ordered sequence within topic            │
│  • Producer: Publishes messages to topics              │
│  • Consumer: Subscribes to topics and processes        │
│  • Consumer Group: Multiple consumers working together │
│  • Offset: Position in partition log                   │
└─────────────────────────────────────────────────────────┘
```

### 2. Docker Compose Setup for Kafka

Let's create a comprehensive Kafka environment setup file.

**File: section-2/notification-service/docker-compose.kafka.yml**

```yaml
version: "3.8"

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - kafka-network

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "29092:29092"
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: false
    networks:
      - kafka-network
    volumes:
      - kafka_data:/var/lib/kafka/data

  schema-registry:
    image: confluentinc/cp-schema-registry:7.4.0
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      - kafka
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "kafka:29092"
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    networks:
      - kafka-network

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka
      - schema-registry
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry:8081
    networks:
      - kafka-network

  # Redis for caching and session management
  redis:
    image: redis:7-alpine
    container_name: kafka-redis
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    networks:
      - kafka-network
    volumes:
      - redis_data:/data

  # PostgreSQL for persistent storage
  postgres:
    image: postgres:15-alpine
    container_name: kafka-postgres
    environment:
      POSTGRES_DB: microservices_events
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password123
    ports:
      - "5432:5432"
    networks:
      - kafka-network
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db.sql:/docker-entrypoint-initdb.d/init-db.sql

volumes:
  kafka_data:
  redis_data:
  postgres_data:

networks:
  kafka-network:
    driver: bridge
```

### 3. Kafka Topics Initialization

**File: section-2/notification-service/kafka-setup.sh**

```bash
#!/bin/bash

echo "Setting up Kafka topics..."

# Wait for Kafka to be ready
echo "Waiting for Kafka to be ready..."
docker exec kafka kafka-topics --bootstrap-server kafka:29092 --list

# Create topics
echo "Creating topics..."

# Order events
docker exec kafka kafka-topics \
  --bootstrap-server kafka:29092 \
  --create \
  --topic order-events \
  --partitions 3 \
  --replication-factor 1

# User events
docker exec kafka kafka-topics \
  --bootstrap-server kafka:29092 \
  --create \
  --topic user-events \
  --partitions 3 \
  --replication-factor 1

# Notification events
docker exec kafka kafka-topics \
  --bootstrap-server kafka:29092 \
  --create \
  --topic notification-events \
  --partitions 3 \
  --replication-factor 1

# Product events
docker exec kafka kafka-topics \
  --bootstrap-server kafka:29092 \
  --create \
  --topic product-events \
  --partitions 3 \
  --replication-factor 1

# Dead letter queue
docker exec kafka kafka-topics \
  --bootstrap-server kafka:29092 \
  --create \
  --topic dead-letter-queue \
  --partitions 1 \
  --replication-factor 1

# Audit events
docker exec kafka kafka-topics \
  --bootstrap-server kafka:29092 \
  --create \
  --topic audit-events \
  --partitions 2 \
  --replication-factor 1

echo "Topics created successfully!"

# List all topics
echo "Available topics:"
docker exec kafka kafka-topics --bootstrap-server kafka:29092 --list
```

## Practical Implementation: Event-Driven Notification Service

### 1. Enhanced Notification Service with Kafka Integration

Let's upgrade our notification service to handle asynchronous events from other services.

**File: section-2/notification-service/src/kafka/kafka.service.ts**

```typescript
import {
  Injectable,
  Logger,
  OnModuleDestroy,
  OnModuleInit,
} from "@nestjs/common";
import { Kafka, Producer, Consumer, EachMessagePayload } from "kafkajs";
import { ConfigService } from "@nestjs/config";

export interface EventMessage {
  eventId: string;
  eventType: string;
  aggregateId: string;
  version: number;
  timestamp: Date;
  data: any;
  metadata: {
    source: string;
    correlationId?: string;
    causationId?: string;
  };
}

@Injectable()
export class KafkaService implements OnModuleInit, OnModuleDestroy {
  private readonly logger = new Logger(KafkaService.name);
  private kafka: Kafka;
  private producer: Producer;
  private consumers: Map<string, Consumer> = new Map();

  constructor(private configService: ConfigService) {
    this.kafka = new Kafka({
      clientId: "notification-service",
      brokers: this.configService
        .get("KAFKA_BROKERS", "localhost:9092")
        .split(","),
      retry: {
        initialRetryTime: 100,
        retries: 8,
      },
    });

    this.producer = this.kafka.producer({
      maxInFlightRequests: 1,
      idempotent: true,
      transactionTimeout: 30000,
    });
  }

  async onModuleInit() {
    await this.connectProducer();
    await this.setupConsumers();
  }

  async onModuleDestroy() {
    await this.producer.disconnect();
    for (const [groupId, consumer] of this.consumers) {
      await consumer.disconnect();
      this.logger.log(`Consumer ${groupId} disconnected`);
    }
  }

  private async connectProducer() {
    try {
      await this.producer.connect();
      this.logger.log("Kafka producer connected successfully");
    } catch (error) {
      this.logger.error("Failed to connect Kafka producer:", error);
      throw error;
    }
  }

  private async setupConsumers() {
    // Setup consumer for order events
    await this.createConsumer("notification-service-orders", ["order-events"]);

    // Setup consumer for user events
    await this.createConsumer("notification-service-users", ["user-events"]);

    // Setup consumer for product events
    await this.createConsumer("notification-service-products", [
      "product-events",
    ]);
  }

  private async createConsumer(groupId: string, topics: string[]) {
    const consumer = this.kafka.consumer({
      groupId,
      sessionTimeout: 30000,
      rebalanceTimeout: 60000,
      heartbeatInterval: 3000,
      retry: {
        initialRetryTime: 100,
        retries: 8,
      },
    });

    try {
      await consumer.connect();
      await consumer.subscribe({
        topics,
        fromBeginning: false,
      });

      await consumer.run({
        eachMessage: async (payload: EachMessagePayload) => {
          await this.handleMessage(payload);
        },
      });

      this.consumers.set(groupId, consumer);
      this.logger.log(
        `Consumer ${groupId} connected and subscribed to topics: ${topics.join(
          ", "
        )}`
      );
    } catch (error) {
      this.logger.error(`Failed to setup consumer ${groupId}:`, error);
      throw error;
    }
  }

  async publishEvent(topic: string, event: EventMessage): Promise<void> {
    try {
      const message = {
        key: event.aggregateId,
        value: JSON.stringify(event),
        headers: {
          eventType: event.eventType,
          source: event.metadata.source,
          timestamp: event.timestamp.toISOString(),
        },
      };

      await this.producer.send({
        topic,
        messages: [message],
      });

      this.logger.log(`Event published to topic ${topic}: ${event.eventType}`);
    } catch (error) {
      this.logger.error(`Failed to publish event to topic ${topic}:`, error);
      // Send to dead letter queue
      await this.sendToDeadLetterQueue(topic, event, error.message);
      throw error;
    }
  }

  private async handleMessage(payload: EachMessagePayload): Promise<void> {
    const { topic, partition, message } = payload;

    try {
      const event: EventMessage = JSON.parse(message.value?.toString() || "{}");

      this.logger.log(
        `Processing message from topic ${topic}, partition ${partition}, offset ${message.offset}: ${event.eventType}`
      );

      // Route to appropriate handler based on event type
      await this.routeEvent(event);

      // Commit the offset manually if needed
      this.logger.log(`Successfully processed event: ${event.eventId}`);
    } catch (error) {
      this.logger.error(
        `Failed to process message from topic ${topic}:`,
        error
      );

      // Send to dead letter queue for failed processing
      await this.sendToDeadLetterQueue(
        topic,
        JSON.parse(message.value?.toString() || "{}"),
        error.message
      );
    }
  }

  private async routeEvent(event: EventMessage): Promise<void> {
    switch (event.eventType) {
      case "OrderCreated":
        await this.handleOrderCreated(event);
        break;
      case "OrderPaid":
        await this.handleOrderPaid(event);
        break;
      case "OrderShipped":
        await this.handleOrderShipped(event);
        break;
      case "UserRegistered":
        await this.handleUserRegistered(event);
        break;
      case "ProductOutOfStock":
        await this.handleProductOutOfStock(event);
        break;
      default:
        this.logger.warn(`Unhandled event type: ${event.eventType}`);
    }
  }

  // Event Handlers
  private async handleOrderCreated(event: EventMessage): Promise<void> {
    const { orderId, customerId, amount } = event.data;

    // Send order confirmation notification
    await this.publishEvent("notification-events", {
      eventId: `notif-${Date.now()}`,
      eventType: "NotificationRequested",
      aggregateId: `notification-${orderId}`,
      version: 1,
      timestamp: new Date(),
      data: {
        type: "email",
        recipient: customerId,
        template: "order_confirmation",
        data: {
          orderId,
          amount,
          orderDate: event.timestamp,
        },
      },
      metadata: {
        source: "notification-service",
        correlationId: event.metadata.correlationId,
        causationId: event.eventId,
      },
    });

    this.logger.log(
      `Order confirmation notification queued for order: ${orderId}`
    );
  }

  private async handleOrderPaid(event: EventMessage): Promise<void> {
    const { orderId, customerId, paymentMethod } = event.data;

    await this.publishEvent("notification-events", {
      eventId: `notif-${Date.now()}`,
      eventType: "NotificationRequested",
      aggregateId: `notification-${orderId}-payment`,
      version: 1,
      timestamp: new Date(),
      data: {
        type: "sms",
        recipient: customerId,
        template: "payment_confirmation",
        data: {
          orderId,
          paymentMethod,
          paidAt: event.timestamp,
        },
      },
      metadata: {
        source: "notification-service",
        correlationId: event.metadata.correlationId,
        causationId: event.eventId,
      },
    });

    this.logger.log(
      `Payment confirmation notification queued for order: ${orderId}`
    );
  }

  private async handleOrderShipped(event: EventMessage): Promise<void> {
    const { orderId, customerId, trackingNumber, estimatedDelivery } =
      event.data;

    await this.publishEvent("notification-events", {
      eventId: `notif-${Date.now()}`,
      eventType: "NotificationRequested",
      aggregateId: `notification-${orderId}-shipping`,
      version: 1,
      timestamp: new Date(),
      data: {
        type: "email",
        recipient: customerId,
        template: "order_shipped",
        data: {
          orderId,
          trackingNumber,
          estimatedDelivery,
        },
      },
      metadata: {
        source: "notification-service",
        correlationId: event.metadata.correlationId,
        causationId: event.eventId,
      },
    });

    this.logger.log(`Shipping notification queued for order: ${orderId}`);
  }

  private async handleUserRegistered(event: EventMessage): Promise<void> {
    const { userId, email, firstName } = event.data;

    await this.publishEvent("notification-events", {
      eventId: `notif-${Date.now()}`,
      eventType: "NotificationRequested",
      aggregateId: `notification-user-${userId}`,
      version: 1,
      timestamp: new Date(),
      data: {
        type: "email",
        recipient: userId,
        template: "welcome",
        data: {
          firstName,
          email,
          registeredAt: event.timestamp,
        },
      },
      metadata: {
        source: "notification-service",
        correlationId: event.metadata.correlationId,
        causationId: event.eventId,
      },
    });

    this.logger.log(`Welcome notification queued for user: ${userId}`);
  }

  private async handleProductOutOfStock(event: EventMessage): Promise<void> {
    const { productId, productName } = event.data;

    // This could trigger notifications to users who have this product in wishlist
    await this.publishEvent("notification-events", {
      eventId: `notif-${Date.now()}`,
      eventType: "NotificationRequested",
      aggregateId: `notification-product-${productId}`,
      version: 1,
      timestamp: new Date(),
      data: {
        type: "admin_alert",
        template: "product_out_of_stock",
        data: {
          productId,
          productName,
          outOfStockAt: event.timestamp,
        },
      },
      metadata: {
        source: "notification-service",
        correlationId: event.metadata.correlationId,
        causationId: event.eventId,
      },
    });

    this.logger.log(
      `Product out of stock alert queued for product: ${productId}`
    );
  }

  private async sendToDeadLetterQueue(
    originalTopic: string,
    event: any,
    errorMessage: string
  ): Promise<void> {
    try {
      const dlqEvent = {
        originalTopic,
        originalEvent: event,
        error: errorMessage,
        timestamp: new Date().toISOString(),
        retryCount: 0,
      };

      await this.producer.send({
        topic: "dead-letter-queue",
        messages: [
          {
            key: event.aggregateId || "unknown",
            value: JSON.stringify(dlqEvent),
            headers: {
              originalTopic,
              error: errorMessage,
            },
          },
        ],
      });

      this.logger.log(
        `Event sent to dead letter queue from topic: ${originalTopic}`
      );
    } catch (dlqError) {
      this.logger.error("Failed to send to dead letter queue:", dlqError);
    }
  }

  // Health check method
  async getHealth(): Promise<{ status: string; details: any }> {
    try {
      const admin = this.kafka.admin();
      await admin.connect();

      const topics = await admin.listTopics();
      await admin.disconnect();

      return {
        status: "healthy",
        details: {
          connectedTopics: topics.length,
          activeConsumers: this.consumers.size,
          producerConnected: true,
        },
      };
    } catch (error) {
      return {
        status: "unhealthy",
        details: {
          error: error.message,
          activeConsumers: this.consumers.size,
          producerConnected: false,
        },
      };
    }
  }
}
```

### 2. Enhanced Order Service as Event Publisher

Let's enhance the order service to publish events to Kafka when orders are created or updated.

**File: section-2/order-service/src/events/event.publisher.ts**

```typescript
import { Injectable, Logger } from "@nestjs/common";
import { Kafka, Producer } from "kafkajs";
import { v4 as uuidv4 } from "uuid";

export interface DomainEvent {
  eventId: string;
  eventType: string;
  aggregateId: string;
  version: number;
  timestamp: Date;
  data: any;
  metadata: {
    source: string;
    correlationId?: string;
    causationId?: string;
  };
}

@Injectable()
export class EventPublisher {
  private readonly logger = new Logger(EventPublisher.name);
  private kafka: Kafka;
  private producer: Producer;

  constructor() {
    this.kafka = new Kafka({
      clientId: "order-service",
      brokers: [process.env.KAFKA_BROKERS || "localhost:9092"],
    });

    this.producer = this.kafka.producer();
  }

  async onModuleInit() {
    await this.producer.connect();
    this.logger.log("Event publisher connected to Kafka");
  }

  async onModuleDestroy() {
    await this.producer.disconnect();
  }

  async publishOrderEvent(
    eventType: string,
    orderId: string,
    data: any,
    correlationId?: string
  ): Promise<void> {
    const event: DomainEvent = {
      eventId: uuidv4(),
      eventType,
      aggregateId: orderId,
      version: 1,
      timestamp: new Date(),
      data,
      metadata: {
        source: "order-service",
        correlationId,
      },
    };

    try {
      await this.producer.send({
        topic: "order-events",
        messages: [
          {
            key: orderId,
            value: JSON.stringify(event),
            headers: {
              eventType,
              aggregateId: orderId,
              timestamp: event.timestamp.toISOString(),
            },
          },
        ],
      });

      this.logger.log(`Published ${eventType} event for order ${orderId}`);
    } catch (error) {
      this.logger.error(
        `Failed to publish ${eventType} event for order ${orderId}:`,
        error
      );
      throw error;
    }
  }

  async publishOrderCreated(
    orderId: string,
    orderData: any,
    correlationId?: string
  ): Promise<void> {
    await this.publishOrderEvent(
      "OrderCreated",
      orderId,
      {
        orderId,
        customerId: orderData.customerId,
        amount: orderData.totalAmount,
        currency: orderData.currency || "USD",
        items: orderData.items,
        shippingAddress: orderData.shippingAddress,
        orderDate: new Date(),
      },
      correlationId
    );
  }

  async publishOrderPaid(
    orderId: string,
    paymentData: any,
    correlationId?: string
  ): Promise<void> {
    await this.publishOrderEvent(
      "OrderPaid",
      orderId,
      {
        orderId,
        customerId: paymentData.customerId,
        amount: paymentData.amount,
        paymentMethod: paymentData.paymentMethod,
        transactionId: paymentData.transactionId,
        paidAt: new Date(),
      },
      correlationId
    );
  }

  async publishOrderShipped(
    orderId: string,
    shippingData: any,
    correlationId?: string
  ): Promise<void> {
    await this.publishOrderEvent(
      "OrderShipped",
      orderId,
      {
        orderId,
        customerId: shippingData.customerId,
        trackingNumber: shippingData.trackingNumber,
        carrier: shippingData.carrier,
        estimatedDelivery: shippingData.estimatedDelivery,
        shippedAt: new Date(),
      },
      correlationId
    );
  }

  async publishOrderCancelled(
    orderId: string,
    cancellationData: any,
    correlationId?: string
  ): Promise<void> {
    await this.publishOrderEvent(
      "OrderCancelled",
      orderId,
      {
        orderId,
        customerId: cancellationData.customerId,
        reason: cancellationData.reason,
        refundAmount: cancellationData.refundAmount,
        cancelledAt: new Date(),
      },
      correlationId
    );
  }
}
```

### 3. Enhanced Order Service Integration

**File: section-2/order-service/src/services/order.service.ts**

```typescript
import { Injectable, Logger, NotFoundException } from "@nestjs/common";
import { InjectRepository } from "@nestjs/typeorm";
import { Repository } from "typeorm";
import { Order } from "../entities/order.entity";
import { CreateOrderDto } from "../dtos/create-order.dto";
import { EventPublisher } from "../events/event.publisher";
import { v4 as uuidv4 } from "uuid";

export enum OrderStatus {
  PENDING = "pending",
  PAID = "paid",
  PROCESSING = "processing",
  SHIPPED = "shipped",
  DELIVERED = "delivered",
  CANCELLED = "cancelled",
}

@Injectable()
export class OrderService {
  private readonly logger = new Logger(OrderService.name);

  constructor(
    @InjectRepository(Order)
    private orderRepository: Repository<Order>,
    private eventPublisher: EventPublisher
  ) {}

  async createOrder(createOrderDto: CreateOrderDto): Promise<Order> {
    const correlationId = uuidv4();

    try {
      // Create order in database
      const order = this.orderRepository.create({
        ...createOrderDto,
        status: OrderStatus.PENDING,
        createdAt: new Date(),
        correlationId,
      });

      const savedOrder = await this.orderRepository.save(order);
      this.logger.log(`Order created: ${savedOrder.id}`);

      // Publish OrderCreated event
      await this.eventPublisher.publishOrderCreated(
        savedOrder.id,
        savedOrder,
        correlationId
      );

      return savedOrder;
    } catch (error) {
      this.logger.error(`Failed to create order: ${error.message}`);
      throw error;
    }
  }

  async processPayment(orderId: string, paymentData: any): Promise<Order> {
    const order = await this.findOrderById(orderId);

    if (order.status !== OrderStatus.PENDING) {
      throw new Error(
        `Cannot process payment for order in status: ${order.status}`
      );
    }

    try {
      // Simulate payment processing
      order.status = OrderStatus.PAID;
      order.paymentData = paymentData;
      order.paidAt = new Date();

      const updatedOrder = await this.orderRepository.save(order);
      this.logger.log(`Payment processed for order: ${orderId}`);

      // Publish OrderPaid event
      await this.eventPublisher.publishOrderPaid(
        orderId,
        {
          customerId: order.customerId,
          amount: order.totalAmount,
          paymentMethod: paymentData.paymentMethod,
          transactionId: paymentData.transactionId,
        },
        order.correlationId
      );

      return updatedOrder;
    } catch (error) {
      this.logger.error(
        `Failed to process payment for order ${orderId}: ${error.message}`
      );
      throw error;
    }
  }

  async shipOrder(orderId: string, shippingData: any): Promise<Order> {
    const order = await this.findOrderById(orderId);

    if (order.status !== OrderStatus.PAID) {
      throw new Error(`Cannot ship order in status: ${order.status}`);
    }

    try {
      order.status = OrderStatus.SHIPPED;
      order.shippingData = shippingData;
      order.shippedAt = new Date();

      const updatedOrder = await this.orderRepository.save(order);
      this.logger.log(`Order shipped: ${orderId}`);

      // Publish OrderShipped event
      await this.eventPublisher.publishOrderShipped(
        orderId,
        {
          customerId: order.customerId,
          trackingNumber: shippingData.trackingNumber,
          carrier: shippingData.carrier,
          estimatedDelivery: shippingData.estimatedDelivery,
        },
        order.correlationId
      );

      return updatedOrder;
    } catch (error) {
      this.logger.error(`Failed to ship order ${orderId}: ${error.message}`);
      throw error;
    }
  }

  async cancelOrder(orderId: string, reason: string): Promise<Order> {
    const order = await this.findOrderById(orderId);

    if (["shipped", "delivered", "cancelled"].includes(order.status)) {
      throw new Error(`Cannot cancel order in status: ${order.status}`);
    }

    try {
      order.status = OrderStatus.CANCELLED;
      order.cancellationReason = reason;
      order.cancelledAt = new Date();

      const updatedOrder = await this.orderRepository.save(order);
      this.logger.log(`Order cancelled: ${orderId}`);

      // Publish OrderCancelled event
      await this.eventPublisher.publishOrderCancelled(
        orderId,
        {
          customerId: order.customerId,
          reason,
          refundAmount: order.totalAmount,
        },
        order.correlationId
      );

      return updatedOrder;
    } catch (error) {
      this.logger.error(`Failed to cancel order ${orderId}: ${error.message}`);
      throw error;
    }
  }

  private async findOrderById(orderId: string): Promise<Order> {
    const order = await this.orderRepository.findOne({
      where: { id: orderId },
    });
    if (!order) {
      throw new NotFoundException(`Order not found: ${orderId}`);
    }
    return order;
  }

  async getOrder(orderId: string): Promise<Order> {
    return this.findOrderById(orderId);
  }

  async getOrdersByCustomer(customerId: string): Promise<Order[]> {
    return this.orderRepository.find({
      where: { customerId },
      order: { createdAt: "DESC" },
    });
  }

  async getAllOrders(
    page: number = 1,
    limit: number = 10
  ): Promise<{ orders: Order[]; total: number; pages: number }> {
    const [orders, total] = await this.orderRepository.findAndCount({
      skip: (page - 1) * limit,
      take: limit,
      order: { createdAt: "DESC" },
    });

    return {
      orders,
      total,
      pages: Math.ceil(total / limit),
    };
  }
}
```

## Error Handling and Resilience Patterns

### 1. Dead Letter Queue Management

```
┌─────────────────────────────────────────────────────────┐
│              DEAD LETTER QUEUE PATTERN                 │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  Message Processing Flow with DLQ:                    │
│                                                         │
│  1. Normal Processing:                                 │
│  ┌─────────────────────────────────────────────────────┐│
│  │ Producer → Topic → Consumer → Success → Ack        ││
│  │                                                     ││
│  │ If successful, message is acknowledged and removed  ││
│  └─────────────────────────────────────────────────────┘│
│                                                         │
│  2. Error Handling with Retry:                        │
│  ┌─────────────────────────────────────────────────────┐│
│  │ Consumer → Error → Retry → Error → DLQ             ││
│  │            │        │       │                      ││
│  │            │        │       └── Max retries        ││
│  │            │        └────────── Exponential        ││
│  │            │                   backoff             ││
│  │            └──────────────────── Log error         ││
│  └─────────────────────────────────────────────────────┘│
│                                                         │
│  3. DLQ Processing:                                    │
│  ┌─────────────────────────────────────────────────────┐│
│  │ Dead Letter Queue                                   ││
│  │      │                                              ││
│  │      ├── Manual Review                              ││
│  │      ├── Fix and Replay                             ││
│  │      ├── Alert Operations Team                      ││
│  │      └── Archive after investigation               ││
│  └─────────────────────────────────────────────────────┘│
│                                                         │
│  DLQ Message Structure:                                │
│  ┌─────────────────────────────────────────────────────┐│
│  │ {                                                   ││
│  │   "originalTopic": "order-events",                  ││
│  │   "originalPartition": 0,                           ││
│  │   "originalOffset": 1234,                           ││
│  │   "failureReason": "Database connection timeout",   ││
│  │   "retryCount": 3,                                  ││
│  │   "firstFailureTimestamp": "2023-12-01T10:00:00Z",  ││
│  │   "lastFailureTimestamp": "2023-12-01T10:15:00Z",   ││
│  │   "originalMessage": { ... },                       ││
│  │   "stackTrace": "...",                              ││
│  │   "serviceName": "notification-service",            ││
│  │   "serviceVersion": "1.2.3"                         ││
│  │ }                                                   ││
│  └─────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────┘
```

### 2. Circuit Breaker Pattern for External Dependencies

**File: section-2/notification-service/src/utils/circuit-breaker.ts**

```typescript
export enum CircuitState {
  CLOSED = "CLOSED",
  OPEN = "OPEN",
  HALF_OPEN = "HALF_OPEN",
}

export interface CircuitBreakerOptions {
  failureThreshold: number;
  recoveryTimeout: number;
  monitoringPeriod: number;
  expectedErrors?: string[];
}

export class CircuitBreaker {
  private state: CircuitState = CircuitState.CLOSED;
  private failureCount = 0;
  private lastFailureTime: Date | null = null;
  private successCount = 0;

  constructor(
    private readonly options: CircuitBreakerOptions,
    private readonly serviceName: string
  ) {}

  async execute<T>(operation: () => Promise<T>): Promise<T> {
    if (this.state === CircuitState.OPEN) {
      if (this.shouldAttemptReset()) {
        this.state = CircuitState.HALF_OPEN;
        console.log(
          `Circuit breaker ${this.serviceName}: Moving to HALF_OPEN state`
        );
      } else {
        throw new Error(`Circuit breaker ${this.serviceName} is OPEN`);
      }
    }

    try {
      const result = await operation();
      this.onSuccess();
      return result;
    } catch (error) {
      this.onFailure(error as Error);
      throw error;
    }
  }

  private onSuccess(): void {
    this.failureCount = 0;
    this.lastFailureTime = null;

    if (this.state === CircuitState.HALF_OPEN) {
      this.successCount++;
      if (this.successCount >= 3) {
        // Require multiple successes to close
        this.state = CircuitState.CLOSED;
        this.successCount = 0;
        console.log(
          `Circuit breaker ${this.serviceName}: Closed after successful recovery`
        );
      }
    }
  }

  private onFailure(error: Error): void {
    this.lastFailureTime = new Date();
    this.failureCount++;

    if (this.state === CircuitState.HALF_OPEN) {
      this.state = CircuitState.OPEN;
      console.log(
        `Circuit breaker ${this.serviceName}: Opened from HALF_OPEN due to failure`
      );
    } else if (this.failureCount >= this.options.failureThreshold) {
      this.state = CircuitState.OPEN;
      console.log(
        `Circuit breaker ${this.serviceName}: Opened due to failure threshold`
      );
    }
  }

  private shouldAttemptReset(): boolean {
    if (!this.lastFailureTime) return false;

    const timeSinceLastFailure = Date.now() - this.lastFailureTime.getTime();
    return timeSinceLastFailure >= this.options.recoveryTimeout;
  }

  getState(): CircuitState {
    return this.state;
  }

  getStats(): {
    state: CircuitState;
    failureCount: number;
    lastFailureTime: Date | null;
  } {
    return {
      state: this.state,
      failureCount: this.failureCount,
      lastFailureTime: this.lastFailureTime,
    };
  }
}
```

## Testing and Monitoring

### 1. Integration Testing with Kafka

**File: section-2/notification-service/test/kafka.integration.spec.ts**

```typescript
import { Test, TestingModule } from "@nestjs/testing";
import { KafkaService } from "../src/kafka/kafka.service";
import { ConfigService } from "@nestjs/config";
import { Kafka } from "kafkajs";

describe("Kafka Integration Tests", () => {
  let kafkaService: KafkaService;
  let kafka: Kafka;

  beforeAll(async () => {
    // Setup test Kafka instance
    kafka = new Kafka({
      clientId: "test-client",
      brokers: ["localhost:9092"],
    });

    const module: TestingModule = await Test.createTestingModule({
      providers: [
        KafkaService,
        {
          provide: ConfigService,
          useValue: {
            get: jest.fn((key: string) => {
              if (key === "KAFKA_BROKERS") return "localhost:9092";
              return null;
            }),
          },
        },
      ],
    }).compile();

    kafkaService = module.get<KafkaService>(KafkaService);
    await kafkaService.onModuleInit();
  });

  afterAll(async () => {
    await kafkaService.onModuleDestroy();
  });

  describe("Event Publishing", () => {
    it("should publish order created event successfully", async () => {
      const orderEvent = {
        eventId: "test-event-1",
        eventType: "OrderCreated",
        aggregateId: "order-123",
        version: 1,
        timestamp: new Date(),
        data: {
          orderId: "order-123",
          customerId: "customer-456",
          amount: 99.99,
          items: [{ productId: "prod-1", quantity: 2, price: 49.99 }],
        },
        metadata: {
          source: "order-service",
          correlationId: "test-correlation-1",
        },
      };

      await expect(
        kafkaService.publishEvent("order-events", orderEvent)
      ).resolves.not.toThrow();
    });

    it("should handle publish failures gracefully", async () => {
      const invalidEvent = {
        eventId: "test-event-2",
        eventType: "InvalidEvent",
        aggregateId: null, // Invalid aggregate ID
        version: 1,
        timestamp: new Date(),
        data: {},
        metadata: {
          source: "test-service",
        },
      };

      // Should send to DLQ on failure
      await expect(
        kafkaService.publishEvent("non-existent-topic", invalidEvent)
      ).rejects.toThrow();
    });
  });

  describe("Health Check", () => {
    it("should return healthy status when Kafka is available", async () => {
      const health = await kafkaService.getHealth();

      expect(health.status).toBe("healthy");
      expect(health.details).toHaveProperty("connectedTopics");
      expect(health.details).toHaveProperty("activeConsumers");
      expect(health.details.producerConnected).toBe(true);
    });
  });

  describe("Message Processing", () => {
    it("should process valid events without errors", async () => {
      // This would require setting up test consumers
      // and verifying message processing
      expect(true).toBe(true); // Placeholder
    });

    it("should send invalid messages to DLQ", async () => {
      // Test DLQ functionality
      expect(true).toBe(true); // Placeholder
    });
  });
});
```

### 2. Load Testing Script

**File: section-2/notification-service/scripts/load-test.js**

```javascript
const { Kafka } = require("kafkajs");
const { v4: uuidv4 } = require("uuid");

const kafka = new Kafka({
  clientId: "load-test-client",
  brokers: ["localhost:9092"],
});

const producer = kafka.producer();

async function runLoadTest() {
  console.log("Starting Kafka load test...");

  await producer.connect();

  const startTime = Date.now();
  const messageCount = 10000;
  const batchSize = 100;

  try {
    for (let i = 0; i < messageCount; i += batchSize) {
      const messages = [];

      for (let j = 0; j < batchSize && i + j < messageCount; j++) {
        const orderEvent = {
          eventId: uuidv4(),
          eventType: "OrderCreated",
          aggregateId: `order-${i + j}`,
          version: 1,
          timestamp: new Date(),
          data: {
            orderId: `order-${i + j}`,
            customerId: `customer-${Math.floor(Math.random() * 1000)}`,
            amount: Math.floor(Math.random() * 500) + 10,
            items: [
              {
                productId: `prod-${Math.floor(Math.random() * 100)}`,
                quantity: Math.floor(Math.random() * 5) + 1,
                price: Math.floor(Math.random() * 100) + 10,
              },
            ],
          },
          metadata: {
            source: "load-test",
            correlationId: uuidv4(),
          },
        };

        messages.push({
          key: orderEvent.aggregateId,
          value: JSON.stringify(orderEvent),
          headers: {
            eventType: orderEvent.eventType,
            timestamp: orderEvent.timestamp.toISOString(),
          },
        });
      }

      await producer.send({
        topic: "order-events",
        messages,
      });

      if ((i + batchSize) % 1000 === 0) {
        console.log(`Sent ${i + batchSize} messages...`);
      }
    }

    const endTime = Date.now();
    const duration = endTime - startTime;
    const messagesPerSecond = Math.floor(messageCount / (duration / 1000));

    console.log(`Load test completed!`);
    console.log(`Total messages: ${messageCount}`);
    console.log(`Duration: ${duration}ms`);
    console.log(`Messages per second: ${messagesPerSecond}`);
  } catch (error) {
    console.error("Load test failed:", error);
  } finally {
    await producer.disconnect();
  }
}

// Run the load test
runLoadTest().catch(console.error);
```

### 3. Monitoring Dashboard Configuration

**File: section-2/notification-service/monitoring/grafana-dashboard.json**

```json
{
  "dashboard": {
    "id": null,
    "title": "Microservices Event Processing",
    "tags": ["microservices", "kafka", "events"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "Message Throughput",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(kafka_messages_consumed_total[5m])",
            "legendFormat": "Messages/sec - {{topic}}"
          }
        ],
        "yAxes": [
          {
            "label": "Messages per second"
          }
        ]
      },
      {
        "id": 2,
        "title": "Consumer Lag",
        "type": "graph",
        "targets": [
          {
            "expr": "kafka_consumer_lag",
            "legendFormat": "Lag - {{consumer_group}} - {{partition}}"
          }
        ],
        "yAxes": [
          {
            "label": "Messages behind"
          }
        ]
      },
      {
        "id": 3,
        "title": "Error Rate",
        "type": "singlestat",
        "targets": [
          {
            "expr": "rate(kafka_processing_errors_total[5m])",
            "legendFormat": "Errors/sec"
          }
        ],
        "thresholds": "0,0.1,1",
        "colorBackground": true
      },
      {
        "id": 4,
        "title": "Dead Letter Queue Size",
        "type": "singlestat",
        "targets": [
          {
            "expr": "kafka_topic_messages{topic=\"dead-letter-queue\"}",
            "legendFormat": "DLQ Messages"
          }
        ],
        "thresholds": "0,10,100",
        "colorBackground": true
      },
      {
        "id": 5,
        "title": "Service Health",
        "type": "table",
        "targets": [
          {
            "expr": "up{job=\"microservices\"}",
            "format": "table",
            "instant": true
          }
        ],
        "columns": [
          {
            "text": "Service",
            "value": "instance"
          },
          {
            "text": "Status",
            "value": "Value"
          }
        ]
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "5s"
  }
}
```

This comprehensive asynchronous communication implementation demonstrates real-world event-driven architecture patterns, providing a robust foundation for scalable microservices communication. The solution includes proper error handling, monitoring, and testing strategies essential for production systems.

---

## Summary and Best Practices

### Key Takeaways

1. **Event-Driven Architecture**: Enables loose coupling and better scalability
2. **Message Durability**: Kafka provides reliable message persistence
3. **Error Handling**: Dead letter queues and circuit breakers ensure resilience
4. **Monitoring**: Comprehensive observability for production systems
5. **Testing**: Load testing and integration testing validate system behavior

### Production Considerations

- Configure appropriate retention policies for topics
- Monitor consumer lag and processing times
- Implement proper security (SASL/SSL) for production
- Use schema registry for message versioning
- Plan for disaster recovery and backup strategies

---

## References and Resources

### Apache Kafka

- [Kafka Documentation](https://kafka.apache.org/documentation/) - Official Apache Kafka documentation
- [Kafka Streams](https://kafka.apache.org/documentation/streams/) - Stream processing with Kafka
- [Confluent Platform](https://docs.confluent.io/) - Enterprise Kafka platform

### Event-Driven Architecture

- [Event Sourcing](https://martinfowler.com/eaaDev/EventSourcing.html) - Martin Fowler's guide to event sourcing
- [CQRS Pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/cqrs) - Command Query Responsibility Segregation
- [Saga Pattern](https://microservices.io/patterns/data/saga.html) - Managing distributed transactions

### Monitoring and Observability

- [KafkaJS Documentation](https://kafka.js.org/) - Node.js Kafka client library
- [Prometheus Kafka Exporter](https://github.com/danielqsj/kafka_exporter) - Kafka metrics for Prometheus
- [Jaeger Tracing](https://www.jaegertracing.io/) - Distributed tracing for microservices
